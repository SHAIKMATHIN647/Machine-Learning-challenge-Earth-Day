{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2MDozJvpvQV",
        "outputId": "1f7cb858-35c2-4864-a9de-8f17542cf1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ approach.txt created!\n"
          ]
        }
      ],
      "source": [
        "# Create the approach.txt file\n",
        "approach_text = \"\"\"\n",
        "Project: Carbon Footprint Estimation\n",
        "\n",
        "Tools Used:\n",
        "- Python\n",
        "- Pandas\n",
        "- Numpy\n",
        "- Scikit-learn (RandomForestRegressor)\n",
        "\n",
        "Approach:\n",
        "1. Loaded the provided train and test datasets.\n",
        "2. Performed preprocessing:\n",
        "   - One-hot encoded categorical variables ('heating_type', 'diet_type').\n",
        "   - Selected only numerical features.\n",
        "3. Trained a Random Forest Regressor model.\n",
        "4. Predicted carbon footprint for test data.\n",
        "\n",
        "Feature Engineering:\n",
        "- Encoded categorical columns.\n",
        "- Selected numeric features.\n",
        "\n",
        "Evaluation:\n",
        "- R2 Score was used to evaluate performance during validation split.\n",
        "\n",
        "Final Step:\n",
        "- Submission CSV was created in correct format: [ID, carbon_footprint].\n",
        "\n",
        "Notes:\n",
        "- RandomForestRegressor with random_state=42.\n",
        "- No missing values found in datasets.\n",
        "\"\"\"\n",
        "\n",
        "with open('approach.txt', 'w') as f:\n",
        "    f.write(approach_text)\n",
        "\n",
        "print(\"✅ approach.txt created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9x1yPv2oqDXa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWDE1_a8qLOQ",
        "outputId": "043af434-ceb4-41ab-dd30-092fd3087091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-numeric columns: Index(['house_area_sqft', 'household_size', 'heating_type', 'diet_type'], dtype='object')\n",
            "Unique values in house_area_sqft: ['2071.62' '1545.31' '2568.69' ... '2549.02' '2576.97' '1763.05']\n",
            "Unique values in household_size: ['8' '3' '2' '6' '1' '4' '5' '7' '_3&BJ' '8A:v|' 'U(+rW' '.Lve(' 't94wg'\n",
            " 'g%Ygm' '9' 'V5MG0' '`|f\"(' '?S\\\\<<' '75@Aa' 'nsF=>' 'H~c)|' ',-Y=p'\n",
            " 'C+#QI' 'w}1=^' ']Fok^' 'Exrni' '*Mrwz' 'Tj5`5' 'i/@i%' 'NS&F!' '&}%ZS'\n",
            " '$pO&I' 't`{&4' '+#\"JP' 'vwWrA' 'abGL%' '10' 'P`(`D' '[>8b1' 'oS$mL'\n",
            " \"/XXN'\" 'u]_o~' '29sS0' '}L@5{' 'U`Eq0' 'iemn%' 'Hk&,$' 'Npgwo' '@|&A}'\n",
            " 'q=T=c' '(H9kM' 'w?n9s' './\"Qq' '8fL[5' 'f(Sqd' ')c,zL' '`+=]_' '&V|2G'\n",
            " 'aYc@0' 'QgFsg' '6X9eI' '0z\\\\>s' 'I<@*(' 'y|\"5}' 'M56jV' 'G,/Aj' 'xe6oY'\n",
            " ']H`mb' 'CG`57' ')DpW(' '5~|L$' 'kO\\\\tG' ']1)q(' 'J)\\\\e7' 'X+i;c' 'EFj@['\n",
            " 'q/IrZ' 'e;[lj' 'eKjw`' 'AUJ\"o' \"9@'R>\" '1Ab\"^' \"L'm6J\" 'keWOm' ',X)dx'\n",
            " 'Q{gp@' 'hv75)' '?%W:p' 'h*_]1' '?cX:}' 'Rnt^Z' 'Rl]ca' 'pW=AX' 'YGxQF'\n",
            " 'rrrCy' 'c/^R6' '/rEk*' '[L;E=' 'j!hxR' 'V[lG2' '^;ZSC' '_D/S1' 'Q[/B>'\n",
            " '%b\">F' '?:ptR' 'W$&Wh' \"h*/'X\" '>>-}2' '>74[V' 'D*dSY' 'HbK/Z' ';G$5\\\\'\n",
            " 'D~X1,' 'Mmr%u' 'SmYZJ' '|6JAU' '#Z)qb' 'R]*K>' \"n'g,S\" '+[oI-' 'E9m-s'\n",
            " 'qaS[#' \"e>'s0\" 'L))+(' 'w1!4,' 'by-?C' 'H&BPy' 'tnF!J' 'fDRaE' 'WGW*>'\n",
            " '^`G)N' 'cyWvL' '28O.o' 'uG;]1' 'SWnB?' 'eJt!|' ',3OBE' 'el`*{' 'b{|eI'\n",
            " 'aJQ/U' '+mj0D' 'Qc#+L' 'J!y(j' '24goN' 'C#2r8' 'A`?ER' '\\\\Fd#_' 'L<b.L'\n",
            " 'H^rJn' '_6,e$' 'Hn!?A' 'M#hMg' 'to7I2' 'S\\\\2o8' 'PEj;G' 'LGoru' '2RP8~'\n",
            " '.g1/+' \"/'AfU\" 'd7@Rx' '$!u[-' '&RB\\\\1' 'TWP2t' 'V5!=T' '?|6/R' 's*FU9'\n",
            " 'r}\\\\!v' '\\\\]Rsp' ']Fiy$' '*T\"fz' 'mKoR~' 'XKz;@' '2v.\\\\O' 't+-E0'\n",
            " 'Fode^' \"'{6Fq\" \"zp'6A\" ')L~U+' \"?*'K?\" 'NyzY#' '[0<-f' '$qR,$' 'cv)S\\\\'\n",
            " 'SHLGE' \"~@{d'\" 'KMIqi' 'w24^;' 'd}fSe' '#59#[' 'Cu|O<' 'y=NoP' 'GDw}*'\n",
            " \"+v'<n\" 'AR(=~' 'ZB&M#' 'i$>bP' '&GQD!' 'M5X8w' ':<,H-' '3]/,q' 'e?CIX'\n",
            " '}WB7C' '4l]Qf' '*J0cy' 'k3j\"7' '(\\\\[xG' ']kv;n' 'U8opb' '~RrBt' \"ySy'2\"\n",
            " 'T%cA[' '\";gKP' '!=GtK' '=Xn\\\\e' 'nW5.V' 'q=`9$' ';#G1b' '[Y=:X' ':@lIk'\n",
            " '~gHay' 'g{\"0t' 'D/;4.' 'Z>t;N' 'dtD6r' 'r\"^*B' 'UT|%s' 'J%%9N' \"I'(P'\"\n",
            " 'k4\"D>' 'rk\\\\g^' 'a6D~N' \"N}'Q^\" '<J2\"b' 'gxcAx' 'W5&@C' '=w\\\\b}'\n",
            " \"'V\\\\'|\" '|JxeV' 'kt\"4;' 'SaP}!' 't\"_~<' '7;hjO' '9149P' 'Yx&ak' '@jskj'\n",
            " ',=.1V' '5*}!G' '+N`L_' 'RVsG0' 'fi]Ob' \":'E(R\" \"n>dT'\" 'ij3<8' 'DH7x3'\n",
            " '`ybnH' \"qdWw'\" 'c<AOT' '4Nq+*' 'n?%W*' '!mz}6' 'a~+Gi' '_ZCLG' 'L:GAT'\n",
            " 't/7L_' '3Mg;N' 'J2D5[' '~kqP*' 'w.Uzl' 'N_uFv' '+FvN{' 'UY\\\\d&' 'EXf)N'\n",
            " \"'LuhG\" ':~I\\\\C' 'x+P%n' 'C4\"E<' 'eyUIq' '=:OBW' 'aeHlf' '4)i`D' 'xd-;x'\n",
            " 'K:!y/' '1Y@8N' 'HKUV_' '2Mbo=' 'AWwr;' 'W&Al#' '}Mk[~' '7:0Qm' 'fF]{t'\n",
            " '(FwY&' '-8Z:N' '{=v5Z' '(ZE7w' 'q0mSo' \"+'#p~\" '+,+#<' 'v(ksp' 'UYH<}'\n",
            " '(zSYt' 'qW)Lb' 'Koo71' '+tGLJ' '^ci5{' '0=@D>' '%IhLT' '0g%ks' 'CW(#w'\n",
            " 'q+j9\\\\' 'H<-8O' 'q+m=m' 'z;=ot' '6`af-' 'c49^V' '2KkO2' '4@9U$' ')~I)3'\n",
            " '}Rx8-' '-R4IF' 'ql8SM' '^@-JX' 'bdvX#' 't:YC?' 'JfXfH' 'b[`L?' 'GQl:#'\n",
            " '\"\\'g]t' 'm<`Y|' 'l.?NZ' '~z\"g3' 'ymY=4' 'R-NiT' 'lYC0:' 'Y68o5' '.^Qyf'\n",
            " \"oN'[s\" 'YQ?Ii' '{f#st' 'o-<B]' 'KH[#2' 'lYU7b' 'oC0Y]' 'Gh^5n' 'cy^=I'\n",
            " ',6j1}' ';8LD1' '6qR*j' '.D\";6' 'pHZLC' 'c:j~J' \"'*/,S\" 'eSW\"T' '\"Zba5'\n",
            " '%%*)]' 'Naqh,']\n",
            "Unique values in heating_type: ['gas' 'none' 'electric' 'Ty?8J' 'erv2f' '?pLE<' '`kWG`' '?g,NK' \"P'VNr\"\n",
            " '\\'\"@QD' 'b<Y$G' '&Ua<e' 'g5)ot' '7jaO7' 'XA%Eq' \"&0|'b\" 'v?y2M' '`q;G:'\n",
            " 'lV!U~' '~eK%I' 'aLy@k' 'jB^,7' '@_C%?' 'X3SO*' 'zyIUL' '?b&@U' 'tN{=0'\n",
            " ';2=.b' '\\\\dySm' \"e^'W;\" 'Z5!ul' 'xVuOM' 'sCg#)' 'rG!T*' 'Mfce6' 'gJ8=4'\n",
            " 'y>c5c' 'Fu7Vu' '|yvyc' ';p{u9' 'K/<VZ' '@|jM{' '$Lr40' 'Nn9iL' '%.Tj6'\n",
            " '!=Oex' 'D66Z7' '<pBH+' '_&JlF' 'B$|M>' '{&yMr' \"GC;'w\" \"X='gA\" 'E,1.o'\n",
            " ',~Q~t' '|g(.T' 'q1ZS}' '-MeD8' '}1DaI' 'b;.w4' 'aFuOV' '4d39y' '&uOEG'\n",
            " '^sZUK' ';XFK?' '8a\")u' 'oi%z\\\\' 'Q$;8p' 'C]<Cw' 'dcx$h' 'H^il&' 'wbsB8'\n",
            " 'ne~a\"' 'WMvKe' 'klCUk' '*\\\\ES6' 'SlA+a' 'i|D:\\\\' '%MnqN' '<Z#jq' 'Gv-ew'\n",
            " 'O+gJ8' 'eHb<!' 'D|)sL' 'dEi5&' 'V)s{M' '<?gOe' 'ln)I-' 'e\\\\5r@' 'S5K]>'\n",
            " 'zAvWh' '5VDCc' '7u?0c' '+Gx>_' '2YWK6' 'X#%*S' 'ne\\\\}m' '\"#Q\\'K' 'o&D+2'\n",
            " 'aqWjp' '2rQrj' ')<50A' 'A\\\\*&;' '5/xI#' '$:&AH' 'wR@[!' 'VYBHP' 'agk3b'\n",
            " '%oTUi' 'p=cz+' 'Rw{w/' '~ZCLV' 'Z_LT>' 'dW5;l' '5qHV2' '&%XGH' \"E;'Xd\"\n",
            " '{=QV*' '[D<zt' 'l%b?4' 'v+oku' 'Gbp}7' 'r4}^^' 'k5#Sr' '!AEg?' '=**>3'\n",
            " '$nQ7H' 'qGD-W' 'VQh}d' 'L^14K' 'YJ0.b' '&{-6>' ']XO5r' '0/}Sp' 'mS-C@'\n",
            " '}x@Oo' 'e/rpG' 'Y$[5W' '{|5XW' 'uX1;w' 'y^ndv' '|-+O2' 'DN&^E' '?as/K'\n",
            " '1yyCs' 'l=L2B' 'q\\\\uet' '[b]sH' 'c21,e' \"O{'/8\" '#>yd!' '=lb]^' 'z/{fd'\n",
            " '>/kMm' '.|p!:' ':LnP,' 'KjSU7' 'SQLW~' 'W,>_0' ')q|xU' 'C)d>s' 'ie`RX'\n",
            " 'v8Kqz' \"'Y~9:\" 'G?n*1' '[w*86' 'zcVCO' 'SkV;m' 'vtG8:' 'r^V,C' 'yipSp'\n",
            " 'y,5d#' '0Xoa4' 'sj<,X' '^IVr)' '(*zt_' \"Z'P`t\" ':pvWp' '61/o]' 'Hnkwn'\n",
            " 'FcSS{' ',$l/H' '?g>,N' 'I:[x*' '9Ex$Y' '9f=QZ' 'W|U/8' 'fFJ;>' 'S12:m'\n",
            " 'RX}=?' 'CgC68' 'G.+g=' \"7;A,'\" \"'F|w}\" \"48'xZ\" '(wwB;' 'V:m>9' 'M$cCM'\n",
            " 'bTHJ=' 'u+gZB' 'I\"+/{' 've^q\\\\' ':pWN#' '-~0mQ' \"QCI-'\" 'EW_](' 'ia2bH'\n",
            " '4/rnw' 'sgqHE' '0V[ME' '-?67d' 'ez#Ue' '!q-;C' 'kmZ)9' 'a*D&?' '^Sm\\\\L'\n",
            " 'P}]yU' '_g#UJ' 'A@uBX' '=%-KI' 'aL\\\\Ca' 'Su$OV' '+my?s' 'dUj\"%' '6G?l('\n",
            " 'KGPqq' '<AJD1' '*N_RG' 'vw&ag' '_VIF.' 'X(3.P' \"'s$@B\" '~peu+' '}%(?~'\n",
            " '+@B1%' '_J-vT' 'aSwvi' 'f5@&A' 'r\\\\cL.' '^|\"#@' '4g%NI' 'toR4s' ',ci8/'\n",
            " '#&F&L' 'nH$MV' '`>d!I' '1hV_U' ':P#hZ' 'F_RN?' 'R]A&i' '=,}*A' '-{,oT'\n",
            " 'z.Q|(' ')T:CE' '^|Ng,' '8QD7z' 'VtAdu' '\"$ZW<' 'V}wNq' '(wpQn' \"7='e0\"\n",
            " 'bzU/9' '|&%%{' '%i/5!' 'jxXaP' \"[F'dH\" 'Uc}xu' '/;bqE' 'DB>4J' 'L|9_P'\n",
            " '|uH3>' '2J.FA' 'm*LkO' '!9J,c' 'W3kp6' '!Jy(j' '4~c]^' '~k1Or' 'TCcWA'\n",
            " 'TVZ$M' 'fP^/B' 'cv<U-' '_=Xv=' 'D3Tt\"' 'HNR10' ':wePC' \"j[F'l\" 'fMF6F'\n",
            " '%3)59' '+\"M6Z' ',|fF:' \"{'pIp\" \"K*']+\" 'cNXJU' 'v09_a' 'h]YVr' 'b[G*_'\n",
            " 'B,fM_' 'N*F:h' '|S=Md' 'C0m}H' 't`l.R' 'Y#vfL' '#CI-,' 'z\\\\N+r' 'L+&l}'\n",
            " '&I)&>' '@mx5@' '+Y*Se' 'n@&/w' '3nV.&' 'mxaMN' '+exRz' 'wrX\\\\V' 'Wzz0?'\n",
            " 'as}&F' '=E#~C' 'nZJMK' '(Bd;C' '%BL[@' 'Q:2?t' 'U?~>l' 'hVNho' \"$'h?'\"\n",
            " 'hz+-\\\\' '@COtq' 't%wp/' '0b<KR' 'IB)&K' 'ATguk' 'QuG5R' '(NjPz' '?g\"m1'\n",
            " 'YU}j|' 'G9q:q' 'xg]<`' '2=wP!' 'oAZbB' 'c|{X@' '0|=6T' '>p_h1' '&Qm&p'\n",
            " '{\"J-o' 'e8J,x' '1+B#(' 'oK8p`' 'P:Pl~' \"k'F{y\" 'G+?Ot' 'xhV[b']\n",
            "Unique values in diet_type: ['vegetarian' 'omnivore' 'vegan']\n",
            "Validation R2 Score: 0.44091267006141055\n"
          ]
        }
      ],
      "source": [
        "# 1. Load data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# # 2. Preprocessing\n",
        "# categorical_cols = ['heating_type', 'diet_type']\n",
        "# for col in categorical_cols:\n",
        "#     le = LabelEncoder()\n",
        "#     train[col] = le.fit_transform(train[col])\n",
        "#     test[col] = le.transform(test[col])\n",
        "# 🛠 Safe One-Hot Encoding (no crash)\n",
        "full_data = pd.concat([train.drop(['carbon_footprint'], axis=1), test], axis=0)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "full_data = pd.get_dummies(full_data, columns=['heating_type', 'diet_type'])\n",
        "\n",
        "# Split back\n",
        "train_encoded = full_data.iloc[:train.shape[0], :]\n",
        "test_encoded = full_data.iloc[train.shape[0]:, :]\n",
        "\n",
        "# Final features\n",
        "X = train_encoded.drop(['ID'], axis=1)\n",
        "y = train['carbon_footprint']\n",
        "test_features = test_encoded.drop(['ID'], axis=1)\n",
        "\n",
        "# 3. Separate features and target\n",
        "X = train.drop(['ID', 'carbon_footprint'], axis=1)\n",
        "y = train['carbon_footprint']\n",
        "test_features = test.drop(['ID'], axis=1)\n",
        "\n",
        "# 4. (Optional) Train-test split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for non-numeric columns\n",
        "non_numeric_cols = X_train.select_dtypes(include=['object']).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Look at weird values inside those columns\n",
        "for col in non_numeric_cols:\n",
        "    print(f\"Unique values in {col}: {X_train[col].unique()}\")\n",
        "X_train = X_train.select_dtypes(include=[np.number])\n",
        "X_val = X_val.select_dtypes(include=[np.number])\n",
        "test_features = test_features.select_dtypes(include=[np.number])\n",
        "\n",
        "\n",
        "# Only numeric features\n",
        "X_train = X_train.select_dtypes(include=[np.number])\n",
        "X_val = X_val.select_dtypes(include=[np.number])\n",
        "test_features = test_features.select_dtypes(include=[np.number])\n",
        "\n",
        "# Now model training\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Model training\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Validation\n",
        "val_preds = model.predict(X_val)\n",
        "score = r2_score(y_val, val_preds)\n",
        "print(\"Validation R2 Score:\", score)\n",
        "\n",
        "# 7. Predict for test data\n",
        "test_preds = model.predict(test_features)\n",
        "\n",
        "# 8. Create submission file\n",
        "submission = pd.DataFrame({'ID': test['ID'], 'carbon_footprint': test_preds})\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wr8gcS-hqTiZ"
      },
      "outputs": [],
      "source": [
        "# 7. Predict on the test set\n",
        "test_preds = model.predict(test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmnxSI1zqWfr"
      },
      "outputs": [],
      "source": [
        "# 8. Create Submission File\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test['ID'],  # IDs from test.csv\n",
        "    'carbon_footprint': test_preds  # Your model predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)  # Save CSV (no index column)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
